---
title: "Report on Default of Credit Card Clients Dataset"
author: "Masayoshi Sato"
date: "2021/6/26"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{=tex}
\tableofcontents
\clearpage
```
## Introduction

Finance thought to be a field where machine learning can be effective.

We are not sure that a person is credible enough to lend money. They might be a deadbeat, or struggle in a significant debt, even though they look credible. Traditionally, finding a credible borrower have been a skill and experience nurtured by financial institutions, like banks, credit company. But today's complex economical situation does not

For some security and privacy reason, we do not know actual systems introduced in financial institutions,

This paper is written as a final assignment in "HarvardX PH125.9x Data Science: Capstone."

## Dataset

In this paper, we use R packages, "tidyverse[^1]", "DataExplorer[^2]", "gridExtra[^3]", "rpart[^4]", "caret[^5]", and "ranger[^6]".

[^1]: <https://cran.r-project.org/web/packages/tidyverse/index.html>

[^2]: <https://cran.r-project.org/web/packages/DataExplorer/vignettes/dataexplorer-intro.html>

[^3]: <https://cran.r-project.org/web/packages/gridExtra/index.html>

[^4]: <https://cran.r-project.org/web/packages/rpart/rpart.pdf>

[^5]: <https://topepo.github.io/caret/>

[^6]: <https://cran.r-project.org/web/packages/ranger/ranger.pdf>

    Compared to "randomForest", "ranger" is very quick and easy to operate.

```{r Libraries used in this paper, include=FALSE}

if(!require(tidyverse)) install.packages("tidyverse") 
#basic library
if(!require(gridExtra)) install.packages("gridExtra") 
#expansion of ggplot
if(!require(caret)) install.packages("caret") 
#cross validation 
if(!require(rpart)) install.packages("rpart") 
#to make decision tree model
if(!require(rpart.plot)) install.packages("rpart.plot") 
#to plot decision tree
if(!require(DataExplorer)) install.packages("DataExplorer") 
#to do data exploration
if(!require(ranger)) install.packages("ranger") 
#random forest
```

We use a dataset stored in Kaggle.[^7]

[^7]: <https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset>

Data is stored in my GitHub repository. We will use the direct link from my GitHub repository.

```{r Downloading dataset, include=FALSE}

url <-"https://github.com/masa951125/Final_project/raw/main/UCI_Credit_Card.csv"
download.file(url, "original_default.csv")
original_default <- read_csv("original_default.csv")
```

## Data Exploration

First, we need to check the downloaded dataset.

```{r Data exploration (str, summary), echo=FALSE}
str(original_default)
```

```{r}
summary(original_default)
```

No NAs.

Correlation.

```{r}
plot_correlation(original_default)
```

### 1 Outcome

[Kaggle's data explanation says](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset)

Default payment, 1=yes, 0=no

```{r}
summary(original_default$default.payment.next.month)
```

Show distribution graph.

```{r}
ggplot(data=original_default, aes(default.payment.next.month)) +geom_bar()
```

Show proportion of 0,1

```{r}
prop.table(table(original_default$default.payment.next.month))
```

Change name of "default.payment.next.month"

```{r}
n <-which(names(original_default)=="default.payment.next.month")
names(original_default)[n] <- "DEFAULT"
```

Change outcome into factor

```{r}
original_default$DEFAULT <- as.factor(original_default$DEFAULT)
```

### 2 "LIMIT_BAL"

[Kaggle's data explanation says](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset)

Amount of given credit in NT dollars (includes individual and family/supplementary credit

```{r}
summary(original_default$LIMIT_BAL)
```

numeric data

```{r}
ggplot(data=original_default, aes(LIMIT_BAL, fill=DEFAULT)) +geom_histogram()
```

Distribution is skewed right

### 3 "SEX"

[Kaggle's data explanation says](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset)

1=male, 2=female

```{r}
summary(original_default$SEX)
unique(original_default$SEX)
```

categorical data. to make a plot, introducing new character vector.

```{r}
gender <- ifelse(original_default$SEX == 1, "male", "female")
```

```{r}
original_default %>% ggplot(aes(x=gender, fill= DEFAULT)) +
  geom_bar() +
  ggtitle("SEX")+
  stat_count(aes(label = ..count..), geom = "label")# illustrate numbers
```

To make stacked bar graph.

```{r}
original_default %>% ggplot(aes(x=gender, fill= DEFAULT)) +
  geom_bar(position="fill") +
  ggtitle("SEX")
```

There seemed to be little difference between genders.

### 4 "EDUCATION"

[Kaggle's data explanation says](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset);

1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown

```{r}
summary(original_default$EDUCATION)
unique(original_default$EDUCATION)
```

categorical data.

0 is not defined. 0,5 and 6 can be included into 4

```{r}
original_default$EDUCATION <- ifelse( original_default$EDUCATION== 0|
                                      original_default$EDUCATION == 5|
                                      original_default$EDUCATION == 6, 4,
                                      original_default$EDUCATION)
```

Plot.

```{r}
original_default %>% ggplot(aes(x=as.factor(EDUCATION), fill= DEFAULT)) +
  geom_bar() +
  ggtitle("EDUCATION")+
  stat_count(aes(label = ..count..), geom = "label")# illustrate numbers
```

Stacked bar graph.

```{r}
original_default %>% ggplot(aes(x=as.factor(EDUCATION), fill= DEFAULT)) +
  geom_bar(position="fill") +
  ggtitle("EDUCATION")
```

4 is the smallest in terms of default rate. but its numbers are very small.

### 5 "MARRIAGE"

[Kaggle's data explanation says](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset);

marital status. 1=married, 2=single, 3=others.

```{r}
summary(original_default$ MARRIAGE)
unique(original_default$ MARRIAGE)
```

categorical data

0 is not defined. 0 can be included in 3.

```{r}
original_default$MARRIAGE <- ifelse(original_default$MARRIAGE== 0, 3,
                                    original_default$MARRIAGE)
```

Plot.

```{r}
original_default %>% ggplot(aes(x=as.factor(MARRIAGE), fill= DEFAULT)) +
  geom_bar() +
  ggtitle("MARRIAGE")+
  stat_count(aes(label = ..count..), geom = "label")# illustrate numbers
```

Stack bar graph

```{r}
original_default %>% ggplot(aes(x=as.factor(MARRIAGE), fill= DEFAULT)) +
  geom_bar(position="fill") +
  ggtitle("MARRIAGE")
```

There seems to be little difference among the groups.

### 6 "AGE"

```{r}
summary(original_default$AGE)
```

numeric data

Plot.

```{r}
ggplot(data=original_default, aes(AGE, fill=DEFAULT)) +geom_histogram()
```

### 7 "PAY"

[Kaggle's data explanation says](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset);

PAY_0 means repayment status in September, 2005.

-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment delay for nine months and above. Regarding values from PAY_2 to PAY_6, the scales are the same as PAY_0. As the number increases, the date of repayment status goes back in time by a month until April, 2005 which is PAY_6.

. PAY_0.

```{r}
summary(original_default$PAY_0)
unique(original_default$PAY_0)
```

They are categorical data.

Plot.

```{r}
original_default %>% ggplot(aes(x=as.factor(PAY_0), fill= DEFAULT)) +
  geom_bar() +
  ggtitle("PAY_0")+
  stat_count(aes(label = ..count..), geom = "label")# illustrate numbers
```

Stack bar graph PAY_0.

```{r echo=FALSE}
original_default %>% ggplot(aes(x=as.factor(PAY_0), fill= DEFAULT)) +
  geom_bar(position="fill") +
  ggtitle("PAY_0")
```

PAY_2 \~ PAY_6 's structures are almost as same as PAY_0. Show distribution.

```{r echo=FALSE}
#PAY_0
graph_p0 <-
  original_default %>% ggplot(aes(x=as.factor(PAY_0))) +
  geom_bar() +
  ggtitle("PAY_0")

#PAY_2
graph_p2 <-  
  original_default %>% ggplot(aes(x=as.factor(PAY_2))) +
  geom_bar() +
  ggtitle("PAY_2")


#PAY_3
graph_p3 <-  
  original_default %>% ggplot(aes(x=as.factor(PAY_3))) +
  geom_bar() +
  ggtitle("PAY_3")


#PAY_4
graph_p4 <-
original_default %>% ggplot(aes(x=as.factor(PAY_4))) +
  geom_bar() +
  ggtitle("PAY_4")

#PAY_5
graph_p5 <-
  original_default %>% ggplot(aes(x=as.factor(PAY_5))) +
  geom_bar() +
  ggtitle("PAY_5")

#PAY_6
graph_p6 <-
  original_default %>% ggplot(aes(x=as.factor(PAY_6))) +
  geom_bar() +
  ggtitle("PAY_6")


#to show graph side by side, we use "grid.arrange" function in "gridExtra" package
grid.arrange(graph_p0, graph_p2, graph_p3, graph_p4, graph_p5, graph_p6, nrow=2, ncol=3)
```

### 8 "BILL_AMT"

[Kaggle's data explanation says](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset);

BILL_AMT1 is an amount of bill statement in September, 2005 (NT dollar). Likewise PAY, BILL_AMT goes back in time by a month from August to April, 2005 which is BILL_AMT6.

```{r}
summary(original_default$BILL_AMT1)
```

These are numerical data.

Here is BILL_AMT1's plot.

```{r}
ggplot(data=original_default, aes(BILL_AMT1,fill= DEFAULT)) +geom_histogram()
```

From BILL_AMT1 to BILL_AMT6, their structures are almost the same as are shown in following plots.

```{r}
b1 <- ggplot(data=original_default, aes(BILL_AMT1)) +geom_histogram()
b2 <- ggplot(data=original_default, aes(BILL_AMT2)) +geom_histogram()
b3 <- ggplot(data=original_default, aes(BILL_AMT3)) +geom_histogram()
b4 <- ggplot(data=original_default, aes(BILL_AMT4)) +geom_histogram()
b5 <- ggplot(data=original_default, aes(BILL_AMT5)) +geom_histogram()
b6 <- ggplot(data=original_default, aes(BILL_AMT6)) +geom_histogram()
grid.arrange(b1,b2,b3,b4,b5,b6, nrow=2, ncol=3)
```

### 9 "PAY_AMT"

[Kaggle's data explanation says](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset);

PAY_AMT1 is an amount of previous payment in September, 2005 (NT dollar). Likewise BILL_AMT, PAY_AMT goes back in time by a month from August to April, 2005 which is PAY_AMT6.

```{r}
summary(original_default$PAY_AMT1)
```

They are numerical data.

Here is PAY_AMT1's plot.

```{r}
ggplot(data=original_default, aes(PAY_AMT1,fill= DEFAULT)) +geom_histogram()
```

From PAY_AMT1 to PAY_AMT6, their structures are almost the same as are shown in following plots.

```{r}
p1 <- ggplot(data=original_default, aes(PAY_AMT1)) +geom_histogram()
p2 <- ggplot(data=original_default, aes(PAY_AMT2)) +geom_histogram()
p3 <- ggplot(data=original_default, aes(PAY_AMT3)) +geom_histogram()
p4 <- ggplot(data=original_default, aes(PAY_AMT4)) +geom_histogram()
p5 <- ggplot(data=original_default, aes(PAY_AMT5)) +geom_histogram()
p6 <- ggplot(data=original_default, aes(PAY_AMT6)) +geom_histogram()

grid.arrange(p1,p2,p3,p4,p5,p6, nrow=2, ncol=3)
```

## Data Preparation

Remove ID

```{r}
original_default <- original_default %>% select(-ID)
```

Categorical data, change numeric to factor. SEX,EDUCATION,MARRIAGE, PAY_0\~PAY_6 are categorical data

```{r}
original_default <- original_default %>%
  mutate(SEX = as.factor(SEX),
         EDUCATION = as.factor(EDUCATION),
         MARRIAGE = as.factor(MARRIAGE),
         PAY_0 = as.factor(PAY_0),
         PAY_2 = as.factor(PAY_2),
         PAY_3 = as.factor(PAY_3),
         PAY_4 = as.factor(PAY_4),
         PAY_5 = as.factor(PAY_5),
         PAY_6 = as.factor(PAY_6) )
```

Scaling. We use "scale" function to standardize predictors. Categorical data columns. we assume these can be defined as factors.

```{r}
cat_col <- c("SEX", "EDUCATION", "MARRIAGE",
             "PAY_0", "PAY_2", "PAY_3", "PAY_4", "PAY_5", "PAY_6", "DEFAULT")

#all columns
all_col <- names(original_default)

#numerical data columns
num_col <- all_col[-which(all_col %in% cat_col)]

#scaling numerical data
original_default[num_col] <-original_default %>% select(-all_of(cat_col)) %>% scale()
```

Check the dataset.

```{r}
str(original_default)
summary(original_default)
```

Spliting into train_set,validation_set, test_set.

First we split data into test_set, and default.Test_set will be only used as evaluation. We use "createDataPartition" function in "caret" package. Set seed 2021.

```{r}
set.seed(2021, sample.kind = "Rounding")
index_1 <- createDataPartition(original_default$DEFAULT, p=0.2, list=F, times=1)
test_set <- original_default[index_1,]
default <- original_default[-index_1,]
```

As we tune hyperparameters, we split default into train_set and validation_set. Validation set will be used when tuning models.

```{r}
set.seed(2021, sample.kind = "Rounding")
index_2 <- createDataPartition(default$DEFAULT, p=0.2, list=F, times=1)
validation_set <-default[index_2,]
train_set <- default[-index_2,]
```

Check default ratio.

```{r}
#train_set
prop.table(table(train_set$DEFAULT))
#validation_set
prop.table(table(validation_set$DEFAULT))
#test_set
prop.table(table(test_set$DEFAULT))
```

Almost similar ratio.

## Model analysis

### 1 Baseline prediction

All predicted as non_default make factor vectors.

```{r}
base_pred <-factor(numeric(length(test_set$DEFAULT)),levels=c("0","1"))
```

Confusion matrix.

```{r}
confusionMatrix(base_pred, test_set$DEFAULT)
```

We need to find models which exceed these values(except sensitivity). In this model, sensitivity is 1, but specificity is 0. This means the credit company falsely give credit to a person who fail to repay a debt. The loss for the company would be huge.

evaluation method

as this is a classification problem, we calculate accuracy using confusion matrix. However, as is shown in this baseline prediction, default rate is imbalanced. As well as accuracy, we will pay attention to specificity and balanced accuracy.

### 2 Logistic regression

As this is a classification, we use logistic regression. we use "glm" function. There are 24 predictors in the train_set. We use "step regression" to find the best logistic regression model.

Stepwise regression explanation. First we make null-model and full-model.

```{r}
#a null model with no predictors
null_model <- glm(DEFAULT~1, data = train_set, family = binomial(link = "logit"))

#a full model using all of the potential predictors
full_model <- glm(DEFAULT~., data = train_set, family = binomial(link = "logit"))
```

Forward and backward stepwise algorithm.

```{r}
step_mdl   <- step(null_model, 
                   scope = list(lower = null_model, upper = full_model), 
                   direction = "both")
```

Predict by using validation_set. First we predict probabilities and then classify them using cut-off 0.5.

```{r}
step_prob <- predict(step_mdl, validation_set,type="response")
step_pred <- ifelse(step_prob >0.5,1,0)
```

To show accuracy we use confusionMatrix function in caret library.

```{r}
confusionMatrix(as.factor(step_pred), validation_set$DEFAULT)
```

Make a table.

```{r}
results <- tibble(method = "logistic regresion", 
                  Accuracy =confusionMatrix(as.factor(step_pred), validation_set$DEFAULT)$overall[1],
                  Sensitivity =confusionMatrix(as.factor(step_pred), validation_set$DEFAULT)$byClass[1],
                  Specificity =confusionMatrix(as.factor(step_pred), validation_set$DEFAULT)$byClass[2],
                  Balanced_Accuracy =confusionMatrix(as.factor(step_pred), validation_set$DEFAULT)$byClass[11])
                  
results %>% knitr::kable()
```

### 3 Decision tree default model

Use CART classification and regression tree. Rpart \~ using default minsplit=20, cp=0.01.

```{r}
set.seed(2021, sample.kind = "Rounding")
rpart_mdl <-rpart(DEFAULT ~ .,data = train_set)
```

Predict.

```{r}
rpart_pred <- predict(rpart_mdl, validation_set, type="class")
```

Confusion Matrix.

```{r}
confusionMatrix(rpart_pred, validation_set$DEFAULT)
```

Draw decision tree rpart.plot is good function to show decision tree clearly.

```{r}
rpart.plot(rpart_mdl)
```

Find used features.

```{r}
rpart_mdl$variable.importance
```

This model illustrates that PAY_0 is overwhelmingly important.

Make a table

```{r}
results <- bind_rows(
  results,
  tibble(method="CART default",  
         Accuracy = confusionMatrix(rpart_pred, 
                                    validation_set$DEFAULT)$overall[1],
         Sensitivity = confusionMatrix(rpart_pred, 
                                       validation_set$DEFAULT)$byClass[1],
         Specificity = confusionMatrix(rpart_pred, 
                                       validation_set$DEFAULT)$byClass[2],
         Balanced_Accuracy = confusionMatrix(rpart_pred, 
                                             validation_set$DEFAULT)$byClass[11]))
  
results %>% knitr::kable()
```

### 4 Decision tree further tuning

We use "train" function in "caret" package. and tune cp. Cross validation

rpart \~tuning using smaller cp, less than 0.01

```{r}
set.seed(2021, sample.kind = "Rounding")
rpart_tuned_mdl <- train(DEFAULT ~ ., 
                      method = "rpart", 
                      tuneGrid = data.frame(cp = seq(0, 0.01, len = 25)),
                      control = rpart.control(minsplit = 0),
                      data = train_set)
```

Plot cp.

```{r}
plot(rpart_tuned_mdl)
opt_cp <-rpart_tuned_mdl$bestTune
```

Draw decision tree. using rpart.plot.

```{r}
rpart.plot(rpart_tuned_mdl$finalModel)
```

Note: numeric values are scaled

Prediction.

```{r}
rpart_tuned_pred <- predict(rpart_tuned_mdl, validation_set)
```

Confusion matrix

```{r}
confusionMatrix(rpart_tuned_pred, validation_set$DEFAULT)
```

Make a table.

```{r}
results <- bind_rows(
  results,
  tibble(method="CART tuned cp",  
         Accuracy = confusionMatrix(rpart_tuned_pred, validation_set$DEFAULT)$overall[1],
         Sensitivity = confusionMatrix(rpart_tuned_pred, validation_set$DEFAULT)$byClass[1],
         Specificity = confusionMatrix(rpart_tuned_pred, validation_set$DEFAULT)$byClass[2],
         Balanced_Accuracy = confusionMatrix(rpart_tuned_pred, validation_set$DEFAULT)$byClass[11]) )

results %>% knitr::kable()
```

### 5 Random forest default

Using "ranger".

```{r}
set.seed(2021, sample.kind = "Rounding")
rf_mdl <- ranger(
  formula = DEFAULT ~ ., 
  data = train_set,
  probability = F)
```

Model details.

```{r}
rf_mdl
```

Prediction.

```{r}
rf_pred <- predict(rf_mdl, validation_set)$predictions
```

Confusion matrix

```{r}
confusionMatrix(rf_pred, validation_set$DEFAULT)
```

Make a table.

```{r}
results <- bind_rows(
  results,
  tibble(method="random forest default",  
         Accuracy = confusionMatrix(rf_pred, validation_set$DEFAULT)$overall[1],
         Sensitivity = confusionMatrix(rf_pred, validation_set$DEFAULT)$byClass[1],
         Specificity = confusionMatrix(rf_pred, validation_set$DEFAULT)$byClass[2],
         Balanced_Accuracy = confusionMatrix(rf_pred, validation_set$DEFAULT)$byClass[11]) )

results %>% knitr::kable()
```

### 6 Random forest cross validation

Grid search

```{r}
modelLookup("ranger")
```

Make a model.

```{r}
set.seed(2021, sample.kind = "Rounding")
rf_cv_mdl <- train( DEFAULT~ .,
                    data = train_set,
                    method = 'ranger',
                    metric = 'Accuracy',
                    num.trees = 1000,
                    tuneGrid = expand.grid(
                      mtry = 3:10, splitrule = 'gini', min.node.size = 1), 
                    trControl = trainControl(method = 'cv', number = 5))

```

Plot.

```{r}
plot(rf_cv_mdl)
```

Prediction.

```{r}
rf_cv_pred <- predict(rf_cv_mdl, validation_set)
```

Confusion Matrix

```{r}
confusionMatrix(rf_cv_pred, validation_set$DEFAULT)
```

Make a table.

```{r}
results <- bind_rows( results,
                      tibble(
                        method="random forest tuned ",
Accuracy = confusionMatrix(rf_cv_pred, validation_set$DEFAULT)$overall[1],
Sensitivity = confusionMatrix(rf_cv_pred, validation_set$DEFAULT)$byClass[1],
Specificity = confusionMatrix(rf_cv_pred, validation_set$DEFAULT)$byClass[2],
Balanced_Accuracy= confusionMatrix(rf_cv_pred, validation_set$DEFAULT)$byClass[11]) )

results %>% knitr::kable()
```

## Evaluation

Best performance in terms of balanced accuracy is "random forest default model" Best performance in terms of accuracy is "CART default model" Then evaluate by using test_set.

```{r}
final_pred_rpart <- predict(rpart_mdl, test_set,type="class")
confusionMatrix(final_pred_rpart, test_set$DEFAULT)
```

```{r}
final_pred_rf <-predict(rf_mdl, test_set)$predictions
confusionMatrix(final_pred_rf, test_set$DEFAULT)$byClass
```

Make a table.

```{r}
final_results <- tibble( method ="CART default",
                         Accuracy =confusionMatrix(final_pred_rpart, test_set$DEFAULT)$overall[1],
                         Sensitivity =confusionMatrix(final_pred_rpart, test_set$DEFAULT)$byClass[1],
                         Specificity =confusionMatrix(final_pred_rpart, test_set$DEFAULT)$byClass[2],
                         Balanced_Accuracy = confusionMatrix(final_pred_rpart, test_set$DEFAULT)$byClass[11])

final_results <-  bind_rows( final_results, 
                             tibble( method ="Random forest default",
                             Accuracy =confusionMatrix(final_pred_rf, test_set$DEFAULT)$overall[1],
                             Sensitivity =confusionMatrix(final_pred_rf, test_set$DEFAULT)$byClass[1],
                             Specificity =confusionMatrix(final_pred_rf, test_set$DEFAULT)$byClass[2],
                             Balanced_Accuracy = confusionMatrix(final_pred_rf, test_set$DEFAULT)$byClass[11]))

final_results %>% knitr::kable()
```

## Conclusion

\#\#\#
